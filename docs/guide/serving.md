# Serving Models

## Introduction

TensorFlow Serving is a flexible, high-performance serving system for machine
learning models TF Serving is designed for production serving environments. TensorFlow Serving makes
it easy to deploy new algorithms and experiments while keeping the same server
architecture and APIs. TF Serving provides out-of-the-box integration
with TensorFlow models. TF Serving can be easily extended to serve other types of
models and data.

Detailed developer documentation on TensorFlow Serving is available for:

*   [Architecture Overview](https://www.tensorflow.org/tfx/serving/architecture)
*   [Server API](https://www.tensorflow.org/tfx/serving/api_docs/cc/)
*   [REST Client API](https://www.tensorflow.org/tfx/serving/api_rest)
